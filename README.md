# Gradient-Descent

Building and comparing stoichastic gradient descent (SGD) algorithm (using Adam loss) to batch gradient descent (using mean-squared-error (MSE) loss and binary cross-entropy loss).
